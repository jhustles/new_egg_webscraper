{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping NewEgg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import pymongo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "# conn = 'mongodb://localhost:27017'\n",
    "# client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database\n",
    "# db = client.newegg_laptops_db\n",
    "# # Define collection\n",
    "# collection = db.apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Splinter inputs\n",
    "\n",
    "executable_path = {'executable_path': './chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up url that you want to scrape\n",
    "#url = 'https://www.newegg.com/p/pl?N=100006740&page=1&order=RELEASE'\n",
    "url = 'https://www.newegg.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Input\n",
    "\n",
    "#query_input = input(\"What products would you like to scrape?\")\n",
    "query_input = \"Laptops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct web browser to visit the url\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the search bar, and type in \"laptops\"\n",
    "search_box = browser.find_by_id(\"SearchBox2020\").type(query_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the search button! - pretty hard to figure out but did it!\n",
    "\n",
    "#submit = browser.find_by_name(\"fas fa-search\").first.click()\n",
    "#submit = browser.find_link_by_text(\"fas fa-search\").first.click()\n",
    "\n",
    "####### This works!\n",
    "# First looked for all css style sheets in the head\n",
    "# Looked at the names of each css file\n",
    "# and dug up the exact location of the css folder\n",
    "# look for a similar class. narrow it down.\n",
    "# check if it existed\n",
    "# then used the last method\n",
    "#browser.find_by_css(\".fa-search\").first.has_class('fa-search')\n",
    "submit = browser.find_by_css(\".fa-search\").first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the first element which is laptops / notebooks on the side menu far target by class\n",
    "browser.find_by_css(\".filter-box-label\").first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This finds the drop down menu for \"Sort By\" -- will skip this\n",
    "#browser.find_by_id(\"Order_top\").first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# page_soup = soup(browser.html, 'lxml')\n",
    "# page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Sold By: Newegg\" - later add options for each type (later code by xpath for each option)\n",
    "\n",
    "browser.find_by_css(\".form-radiobox-title\").first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#current_page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract total page numbers from results\n",
    "\n",
    "# Use Splinter to grab the current url, to setup request to pull URL\n",
    "current_url = browser.url\n",
    "# Use Request.get() to pull the current url\n",
    "response = requests.get(current_url)\n",
    "#response\n",
    "\n",
    "# Use BeautifulSoup to grab all the HTML using the lxml parser\n",
    "current_page_soup = soup(response.text, 'lxml')\n",
    "\n",
    "# Use BeautifulSoup to extract the total results page number\n",
    "results_pages = current_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "\n",
    "# Find and extract total pages + and add 1 because \n",
    "total_results_pages = int(re.split(\"/\", results_pages)[1]) + 1\n",
    "\n",
    "# This is \"NEXT PAGE BUTTON CLICK\" - This loops thru the total amount of pages by clicking the next page button\n",
    "for turn_page in range(0, total_results_pages):\n",
    "    browser.find_by_xpath('//*[@id=\"bodyArea\"]/section/div/div/div[2]/div/div/div/div[2]/div[1]/div[2]/div[1]/div[2]/div/div[2]/button').click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#browser.find_by_text(\"2\").click()\n",
    "#browser.find_by_css(\".list-tool-pagination-text\").first.has_class('list-tool-pagination-text')#.first.click()\n",
    "#browser.find_by_css(\".btn-group-cell\").has_class('btn-group-cell')\n",
    "\n",
    "#browser.find_by_css(\".btn-group-cell\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Scraper And Exports Out to CSV. Later can figure out how to get it out to PyMongo / Mongo Db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruct webdriver this is the html page to scrape\n",
    "# splinter .html will set the 'source of the page content' \n",
    "html = browser.html\n",
    "# Use beautiful soup to parse the text using html.parser\n",
    "page_soup = soup(html, 'html.parser')\n",
    "\n",
    "# Capture all containers on the page to set up for looping thru later\n",
    "containers = page_soup.find_all(\"div\", class_=\"item-container\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the loop to extract: brand, Title of the product, price-dollar, price-cents,\n",
    "# shipping\n",
    "\n",
    "\n",
    "def newegg_page_scraper(containers):\n",
    "\n",
    "    laptop_brands = []\n",
    "    laptop_models = []\n",
    "    laptop_prices = []\n",
    "    laptop_shipping = []\n",
    "\n",
    "    for con in containers:\n",
    "        page_counter = 0\n",
    "        page_counter += 1\n",
    "        brand_name = con.find_all('a', class_=\"item-brand\")[0].img[\"title\"]\n",
    "        laptop_brands.append(brand_name)\n",
    "        #print(brand_name)\n",
    "\n",
    "        prd_title = con.find_all('a', class_=\"item-title\")[0].text\n",
    "        laptop_models.append(prd_title)\n",
    "\n",
    "        price = con.find_all('li', class_=\"price-current\")[0].text.split()[0]\n",
    "        laptop_prices.append(price)\n",
    "\n",
    "        shipping = contain.find_all('li', class_='price-ship')[0].text.strip()\n",
    "        laptop_shipping.append(shipping)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'brand': laptop_brands,\n",
    "    'model_listing': laptop_models,\n",
    "    'price': laptop_prices,\n",
    "    'shipping': laptop_shipping\n",
    "    })\n",
    "\n",
    "    df.to_csv(f'./output/newgg_laptop_page_{page_counter}.csv')\n",
    "    \n",
    "    return f\"Completed scraping laptop section page number: {page_counter} . \"\n",
    "    \n",
    "newegg_page_scraper(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
