{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "from re import search\n",
    "import copy # might not need this\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import random\n",
    "#import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dt():\n",
    "    global current_date\n",
    "    current_date = str(datetime.datetime.now()).replace(':','.').replace(' ','_')[:-7]\n",
    "    return current_date\n",
    "#return_dt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executable_path = {'executable_path': './chromedriver.exe'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = input(\"Step 1) Please copy and paste your laptop query that you want to webscrape, and press enter: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2)\n",
    "\n",
    "# Function to ask users if they want to watch the Bot (headless = False) work OR not (headless = True)\n",
    "# Lastly, will take you directly to the webpage that was inputted\n",
    "head = ''\n",
    "browser =''\n",
    "def head_on_off(executable_path):\n",
    "    # Have moved two preset variables, head and browser that are both \" = '' \"\n",
    "    # assigning these as global variables enable us to reference them outside and inside the function\n",
    "    global head\n",
    "    global browser\n",
    "    # options creates a bound to an answer\n",
    "    options = [1, 2]\n",
    "    #executable_path = {'executable_path': './chromedriver.exe'}\n",
    "    # for all cases where users input in a value that is not valid\n",
    "    while head not in options:\n",
    "        head = int(input('Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO . Your Answer: '))\n",
    "        if head not in options:\n",
    "            print(\"That was not a valid answer. Please try again. \")\n",
    "    # For cases where users enter in valid options:\n",
    "    if head == options[0]:\n",
    "        print('Head is activated. Please view only the new automated Google Chrome web browser. ')\n",
    "        print('Do not make any adjustments to this automated window while the program runs, as it may produce errors or undesired outputs. ')\n",
    "        browser = Browser('chrome', **executable_path, headless=False)\n",
    "    if head == options[1]:\n",
    "        print('Headless mode activated. No web browser will pop up. Please proceeed. ')\n",
    "        browser = Browser('chrome', **executable_path, headless=True)\n",
    "    # visit the target site\n",
    "    browser.visit(url)\n",
    "    global current_url\n",
    "    current_url = browser.url\n",
    "    #print(current_url)\n",
    "    return current_url\n",
    "\n",
    "#head_on_off(executable_path)\n",
    "#time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3)\n",
    "\n",
    "# Use Splinter to grab the current url, to setup request to pull URL\n",
    "#current_url = browser.url #+ '&Page=' #+ str(turn_page)\n",
    "\n",
    "# Use Request.get() to pull the current url\n",
    "response = requests.get(current_url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4)\n",
    "\n",
    "# Use BeautifulSoup to grab all the HTML using the htmlparser\n",
    "current_page_soup = soup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current_page_soup.find_all(\"a\", class_=\"item-title\")[0].text\n",
    "current_page_soup.find_all(\"div\", class_=\"item-container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 5) Are there scrappable items-contrainers on the page? List first, last and count, also how many pages\n",
    "\n",
    "def scrappable_y_n(current_page_soup):\n",
    "    global containers\n",
    "    containers = current_page_soup.find_all(\"div\", class_=\"item-container\")\n",
    "    \n",
    "    # print first and last objects so users can understand what the output will be\n",
    "    print(\"Preview: expect these scrapped off this page, and for every other total results pages, if there's more than one: \")\n",
    "    print(\"=\"*35)\n",
    "    # max items should be 36\n",
    "    counter = 0\n",
    "    for con in containers:\n",
    "        try:\n",
    "            counter += 1\n",
    "            product_details = con.find_all(\"a\", class_=\"item-title\")[0].text\n",
    "            product_price = con.find_all(\"li\", class_=\"price-current\")[0].text.split()[0]\n",
    "            print(f'{counter}) {product_details} | Price: {product_price}')\n",
    "            print(\"-\"*35)\n",
    "            \n",
    "        except (IndexError) as e:\n",
    "            print(f\"{counter}) This item was not scrappable. Skipped. \")\n",
    "            print(\"-\"*35)\n",
    "            \n",
    "    print(\"=\"*60)\n",
    "    if counter == 0:\n",
    "        print(\"Unable to scrap this link. \")\n",
    "    else:\n",
    "        print(f\"{len(containers)} Scrappable Objects on the page. \")\n",
    "    #return containers\n",
    "#scrappable_y_n(current_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic classes here and then have the function create product objects AND export out to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newegg_page_scraper(containers, turn_page): #before: (containers, turn_page)\n",
    "    \n",
    "    images = []\n",
    "    product_brands = []\n",
    "    product_models = []\n",
    "    product_links = []\n",
    "    #item_numbers = []\n",
    "    product_categories = []\n",
    "    promotions = []\n",
    "    prices = []\n",
    "    shipping_terms = []\n",
    "    page_nums = []\n",
    "\n",
    "\n",
    "    for con in containers:\n",
    "        try:\n",
    "            page_counter = turn_page\n",
    "            page_nums.append(int(turn_page))\n",
    "\n",
    "            image = con.a.img[\"src\"]\n",
    "            #print(image)\n",
    "            images.append(image)\n",
    "\n",
    "            prd_title = con.find_all('a', class_=\"item-title\")[0].text\n",
    "            product_models.append(prd_title)\n",
    "\n",
    "            product_link = con.find_all('a', class_=\"item-title\")[0]['href']\n",
    "            product_links.append(product_link)\n",
    "\n",
    "            shipping = con.find_all('li', class_='price-ship')[0].text.strip().split()[0]\n",
    "            if shipping != \"Free\":\n",
    "                shipping = shipping.replace('$', '')\n",
    "                shipping_terms.append(shipping)\n",
    "            else:\n",
    "                shipping = 0.00\n",
    "                shipping_terms.append(shipping)\n",
    "\n",
    "            brand_name = con.find_all('a', class_=\"item-brand\")[0].img[\"title\"]\n",
    "            product_brands.append(brand_name)\n",
    "\n",
    "        except (IndexError, ValueError) as e:\n",
    "            # if there's no item_brand container, take the Brand from product details\n",
    "            product_brands.append(con.find_all('a', class_=\"item-title\")[0].text.split()[0])\n",
    "            #print(f\"{e} block 1\")\n",
    "\n",
    "        try:\n",
    "            current_promo = con.find_all(\"p\", class_=\"item-promo\")[0].text\n",
    "            promotions.append(current_promo)\n",
    "        except:\n",
    "            promotions.append('null')\n",
    "            #print(f\"{e} block 2\")\n",
    "        try:\n",
    "            price = con.find_all('li', class_=\"price-current\")[0].text.split()[0].replace('$','').replace(',', '')\n",
    "            prices.append(price)\n",
    "        except (IndexError, ValueError) as e:\n",
    "            prices.append('null')\n",
    "            #print(f\"{e} block 3\")\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    #'item_number': item_numbers,\n",
    "    'brand': product_brands,\n",
    "    'model_specifications': product_models,\n",
    "    'price': prices,\n",
    "    'current_promotions': promotions,\n",
    "    'shipping': shipping_terms,\n",
    "    'page_number': page_nums,\n",
    "    'product_links': product_links,\n",
    "    'image_link': images\n",
    "    })\n",
    "\n",
    "    df['product_category'] = current_page_soup.find_all('h1', class_=\"page-title-text\")[0].text\n",
    "    # rearrange columns\n",
    "    df = df[['product_category', 'page_number' ,'brand','model_specifications' ,'current_promotions' ,'price' ,'shipping' ,'product_links','image_link']]\n",
    "    global product_category\n",
    "    product_category = df['product_category'].unique()[0]\n",
    "    # eliminate special characters in a string if it exists\n",
    "    product_category = ''.join(e for e in product_category if e.isalnum())\n",
    "    \n",
    "    #return_list.append(product_category)\n",
    "    global items_scraped\n",
    "    items_scraped = len(df['model_specifications'])\n",
    "    \n",
    "    df.to_csv(f'./processing/{current_date}_{product_category}_{items_scraped}_scraped_page{turn_page}.csv')\n",
    "    return items_scraped, product_category\n",
    "    \n",
    "#df.head()\n",
    "#newegg_page_scraper(containers, turn_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(containers[1].find_all('a', class_=\"item-brand\")[0].img[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "\n",
    "\n",
    "# create a function to return results pages, if exists, otherwise just scrape one page\n",
    "def results_pages():\n",
    "    # Use BeautifulSoup to extract the total results page number\n",
    "    results_pages = current_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "    #print(results_pages)\n",
    "    # Find and extract total pages + and add 1 to ensure proper length of total pages\n",
    "    global total_results_pages\n",
    "    total_results_pages = int(re.split(\"/\", results_pages)[1]) #+ 2 # need to add 2 b/c 'range(inclusive, exclusive)'\n",
    "    #========================================= need to remember to +2, and remove -30\n",
    "    #print(total_results_pages)\n",
    "    total_results_pages = total_results_pages ## ### ## ###\n",
    "    \n",
    "    return total_results_pages\n",
    "#results_pages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working\n",
    "def concatenate(total_results_pages):\n",
    "    \n",
    "    path = f'./processing\\\\'\n",
    "    scraped_pages = glob.glob(path + \"/*.csv\")\n",
    "    concatenate_pages = []\n",
    "    counter = 0\n",
    "    for page in scraped_pages:\n",
    "        df = pd.read_csv(page, index_col=0, header=0)\n",
    "        concatenate_pages.append(df)\n",
    "\n",
    "    compiled_data = pd.concat(concatenate_pages, axis=0, ignore_index=True)\n",
    "    total_items_scraped = len(compiled_data['brand']) # can replace this counter by creating class objects everytime it scrapes\n",
    "    concatenated_output = compiled_data.to_csv(f\"./finished_outputs/{current_date}_{total_items_scraped}_scraped_{total_results_pages}_pages_.csv\")\n",
    "    return concatenated_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_results_pages = 4\n",
    "# concatenate(total_results_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis is working\n",
    "def clean_processing_fldr():\n",
    "    # delete all files in the 'processing folder'\n",
    "    path = f'./processing\\\\'\n",
    "    scraped_pages = glob.glob(path + \"/*.csv\")\n",
    "    if len(scraped_pages) < 1:\n",
    "        print(\"There are no files in the folder to clear. \")\n",
    "    else:\n",
    "        print(f\"Clearing out a total of {len(scraped_pages)} scraped pages in the processing folder... \")\n",
    "        clear_processing_files = []\n",
    "        for page in scraped_pages:\n",
    "            os.remove(page)\n",
    "        \n",
    "    print('Clearing of \"Processing\" folder complete. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webscrape first page, then run page turner, then scraper for every page thereafter\n",
    "# \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning lesson is you can't call a function within a function\n",
    "\n",
    "def page_turner(total_results_pages):\n",
    "    # This is \"NEXT PAGE BUTTON CLICK\" - This loops thru the total amount of pages by clicking the next page button\n",
    "    for turn_page in range(1, total_results_pages):\n",
    "        # set the current url as the target page (aiming the boomerang)\n",
    "        target_url = browser.url\n",
    "\n",
    "        # Use Request.get() - throw the boomerang at the target, retrieve the info, & return back to requestor\n",
    "        response_target = requests.get(target_url)\n",
    "        #response\n",
    "\n",
    "        # Use BeautifulSoup to read grab all the HTML using the lxml parser\n",
    "        target_page_soup = soup(response_target.text, 'html.parser')\n",
    "\n",
    "        # Use BeautifulSoup to extract the total results page number\n",
    "        #results_pages = current_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "        \n",
    "        results_pages = target_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "        #=========================================================\n",
    "        containers = target_page_soup.find_all(\"div\", class_=\"item-container\")\n",
    "        \n",
    "        newegg_page_scraper(containers, turn_page)\n",
    "        \n",
    "        #for i in range(total_results_pages):\n",
    "        x = random.randint(3, 25)\n",
    "        print(f\"{turn_page}) | SLEEPING FOR SECONDS: {x} \")\n",
    "        time.sleep(x)\n",
    "            \n",
    "        browser.find_by_xpath('//*[@id=\"bodyArea\"]/section/div/div/div[2]/div/div/div/div[2]/div[1]/div[2]/div[1]/div[2]/div/div[2]/button').click()\n",
    "\n",
    "    browser.quit()\n",
    "# concatenate(total_results_pages)\n",
    "# clean_processing_fldr()\n",
    "# # clear out processing folder function here - as delete everything to prevent clutter\n",
    "\n",
    "\n",
    "# print(f'WebScraping Complete! All {total_results_pages} have been scraped and saved as {current_date}_{product_category}_scraped_{total_results_pages}_pages_.csv in the \"finished_outputs\" folder')\n",
    "# print('Thank you and hope you found this useful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1) Please copy and paste your laptop query that you want to webscrape, and press enter: https://www.newegg.com/p/pl?N=100006740%204814%20600004343%20600136700%20601296066\n",
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO . Your Answer: 1\n",
      "Head is activated. Please view only the new automated Google Chrome web browser. \n",
      "Do not make any adjustments to this automated window while the program runs, as it may produce errors or undesired outputs. \n",
      "Here are the items that you can expect to be scrapped off this page, and for every other total results pages, if there's more than one: \n",
      "===================================\n",
      "1) HP EliteBook 840 G5 Premium School and Business Laptop (Intel 8th Gen i7-8550U Quad-Core, 16GB RAM, 256GB PCIe SSD, 14\" FHD 1920x1080 Sure View Display, Thunderbolt3, NFC, Fingerprint, Win 10 Pro) | Price: $1,449.00\n",
      "-----------------------------------\n",
      "2) Lenovo ThinkBook 14s Notebook, 14\" FHD Display, Intel Core i7-8565U Upto 4.6GHz, 16GB RAM, 256GB NVMe SSD, AMD Radeon 540X, HDMI, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $999.99\n",
      "-----------------------------------\n",
      "3) HP EliteBook 840 G3 Notebook, 14\" FHD Display, Intel Core i5-6300U Upto 3.0GHz, 16GB RAM, 256GB SSD, VGA, DisplayPort, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $799.99\n",
      "-----------------------------------\n",
      "4) Dell Inspiron 14 3000 Notebook, 14\" HD Display, Intel Core i5-1035G4 Upto 3.7GHz, 16GB RAM, 256GB NVMe SSD, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro S | Price: $649.99\n",
      "-----------------------------------\n",
      "5) HP 14 Notebook, 14\" HD Display, Intel Core i5-1035G4 Upto 3.70GHz, 16GB RAM, 256GB SSD, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $649.99\n",
      "-----------------------------------\n",
      "6) HP 14-DQ1033CL Everyday Value Laptop (Intel i5-1035G4 4-Core, 16GB RAM, 256GB m.2 SATA SSD, 14\" Full HD (1920x1080), Intel Iris Plus Graphics, Wifi, Bluetooth, Webcam, 2xUSB 3.0, Win 10 Pro in S-Mode) | Price: $1,078.80\n",
      "-----------------------------------\n",
      "7) 2019 Lenovo ThinkPad T470 14\" IPS Full HD FHD (1920x1080) Business Laptop (Intel Core i5-6300U, 16GB DDR4 RAM, 256GB PCIe NVMe M.2 SSD) Thunderbolt, Type-C, HDMI RJ-45, Windows 10 Professional 64 Bit | Price: $899.99\n",
      "-----------------------------------\n",
      "8) HP 14-DQ1033CL Everyday Value Laptop (Intel i5-1035G4 4-Core, 16GB RAM, 256GB PCIe SSD, 14\" Full HD (1920x1080), Intel Iris Plus Graphics, Wifi, Bluetooth, Webcam, 2xUSB 3.0, Win 10 Pro in S-Mode) | Price: $1,078.80\n",
      "-----------------------------------\n",
      "9) Newest HP 14 Premium HD Micro-edge Laptop |10Th Intel Core i3-1005G1|16GB DDR4|256GB M.2 SSD| Wi-Fi | Fast Charge| HDMI | Windows 10 | Pale Gold | Price: $491.99\n",
      "-----------------------------------\n",
      "10) Lenovo Flagship ThinkPad T470 14\" FHD Multi-Touch Anti-Glare Laptop | Intel Dual Core i5-6300U | 16GB RAM | 256GB PCIe SSD | WiFi | HDMI | Fingerprint Reader | USB-C | Webcam | Windows 10 Pro | Price: $849.99\n",
      "-----------------------------------\n",
      "11) HP ProBook 645 G4 Notebook, 14\" HD, AMD Quad-Core Ryzen 7 2700U Upto 3.8GHz, 16GB RAM, 256GB SSD, Radeon RX Vega 10, VGA, HDMI, Card Reader, Backlit Keyboard, Wi-Fi, BT, Windows 10 Pro | Price: $999.99\n",
      "-----------------------------------\n",
      "12) HP 14\" HD Customized Laptop | 10th Gen Intel Quad-Core i5-1035G4 Processor up to 3.7 GHz | 16GB RAM 256GB SSD | USB Type-C | HDMI | Card Reader | Windows 10 | Silver Only 3.2lb | Price: $654.52\n",
      "-----------------------------------\n",
      "13) HP ProBook 445R G6 Notebook, 14\" FHD Display, AMD Ryzen 5 3500U Upto 3.7GHz, 16GB RAM, 256GB NVMe SSD, Vega 8, HDMI, DisplayPort via USB-C, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $899.99\n",
      "-----------------------------------\n",
      "14) Dell Inspiron 3493 14\" Customized Laptop | 10th Gen Intel Core i3-1005G1 up to 3.4 GHz | 16GB RAM 256GB SSD | HDMI | Wi-Fi | Bluetooth | Black Only 3.4lb | Windows 10 | Price: $560.05\n",
      "-----------------------------------\n",
      "15) HP EliteBook 840 G3 Notebook, 14\" FHD Display, Intel Core i5-6300U Upto 3.0GHz, 16GB RAM, 256GB SSD + 1TB HDD, VGA, DisplayPort, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $799.99\n",
      "-----------------------------------\n",
      "16) HP 14 Notebook, 14\" HD Display, AMD Ryzen 3 3200U Upto 3.5GHz, 16GB RAM, 256GB SSD, Vega 3, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $519.99\n",
      "-----------------------------------\n",
      "17) Dell Latitude 5400 Notebook, 14\" FHD Touch Display, Intel Core i7-8665U Upto 4.8GHz, 16GB RAM, 256GB NVMe SSD, HDMI, DisplayPort via USB-C, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $1,399.99\n",
      "-----------------------------------\n",
      "18) HP 14 Notebook, 14\" HD Display, Intel Core i5-1035G1 Upto 3.6GHz, 16GB RAM, 256GB NVMe SSD, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $649.99\n",
      "-----------------------------------\n",
      "19) Lenovo Flex 14.0\" Full HD 2-in-1 Touchscreen Notebook,8th Gen Intel Core i5-8265U,16GB DDR4,256GB SSD,Intel UHD 615 Graphics,Wifi-AC,Bluetooth,HDMI,USB,Fingerprint Reader,Windows 10 Pro | Price: $749.00\n",
      "-----------------------------------\n",
      "20) HP 14 Notebook, 14\" HD Display, Intel Core i5-1035G4 Upto 3.70GHz, 16GB RAM, 256GB SSD, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Home | Price: $649.99\n",
      "-----------------------------------\n",
      "21) HP 14 Notebook, 14\" HD Display, AMD A9-9425 Upto 3.7GHz, 16GB RAM, 256GB NVMe SSD, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro S | Price: $699.99\n",
      "-----------------------------------\n",
      "22) HP ProBook 440 G6 Notebook, 14\" HD Display, Intel Core i5-8265U Upto 3.9GHz, 16GB RAM, 256GB SSD, HDMI, MicroDP, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $1,179.99\n",
      "-----------------------------------\n",
      "23) Lenovo ThinkPad E490 Home and Business Laptop (Intel i7-8565U 4-Core, 16GB RAM, 256GB  SATA SSD, 14\" Full HD (1920x1080), Intel UHD 620, Fingerprint, Wifi, Bluetooth, Webcam, 2xUSB 3.0, Win 10 Pro) | Price: $1,258.80\n",
      "-----------------------------------\n",
      "24) 2018 Lenovo ThinkPad X1 Carbon (6th Gen) - Windows 10 Pro - Intel Quad Core i7-8550U, 256GB NVMe-PCIe SSD, 16GB RAM, 14\" FHD IPS (1920x1080) Display, Fingerprint Reader, Black | Price: $1,599.99\n",
      "-----------------------------------\n",
      "25) Newest HP 14 Premium HD Micro-edge Laptop |10Th Intel Quad Core i5-1035G1|16GB DDR4|256GB NVMe SSD+16GB Intel Optane| Wi-Fi 5 (2x2)| Bluetooth | HDMI | Windows 10 Home | Price: $600.99\n",
      "-----------------------------------\n",
      "26) HP 14\" Thin and Light Customized Laptop Intel Core i3-7100U processor 16GB RAM 256GB SSD Upgradable to 16GB RAM 1024GB SSD Windows 10 Ash Silver Only 3.2lb 0.8\" thin USB Type-C | Price: $486.73\n",
      "-----------------------------------\n",
      "27) HP 14\" HD Customized Laptop | 10th Gen Intel Quad-Core i5-1035G4 Processor up to 3.7 GHz | 16GB RAM 256GB SSD | USB Type-C | HDMI | Card Reader | Windows 10 | Silver Only 3.2lb | Price: $654.52\n",
      "-----------------------------------\n",
      "28) HP 14\" HD Notebook, Intel i3-1005G1 Dual Core Upto 3.4GHz, 16GB DDR4, 256GB M.2 SSD, UHD Graphics, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $519.99\n",
      "-----------------------------------\n",
      "29) Acer Swift 3 Narrow Bezel Slim Laptop, 14\" FHD IPS, AMD Ryzen 5 3500U Quad-core up to 3.70 GHz, 16GB DDR4 RAM, 256GB NVMe SSD, USB-C, Vega 8 Graphics, FP Reader, BT, WebCam, Win 10 | Price: $615.89\n",
      "-----------------------------------\n",
      "30) Dell Inspiron 14 3000 Series Laptop, 14\" HD Anti-Glare Display, 10th Gen Intel Quad-Core i5-1035G4  16GB RAM  256GB PCIe SSD + 1TB HDD, WiFi Bluetooth Webcam Win 10 | Price: $781.00\n",
      "-----------------------------------\n",
      "31) Acer Swift 3 Narrow Bezel Slim Laptop, 14\" FHD IPS, AMD Ryzen 5 3500U Quad-core up to 3.70 GHz, 16GB RAM, 256GB NVMe SSD, USB-C, Vega 8 Graphics, RJ-45 LAN, FP Reader, BT, WebCam, Win 10 | Price: $625.07\n",
      "-----------------------------------\n",
      "32) HP 14\" HD Notebook, Ryzen 3 3200u Quad Core Upto 3.6GHz, 16GB DDR4, 256GB M.2 SSD, UHD Graphics, HDMI, Card Reader, Wi-Fi, Bluetooth, USB 3.1, Windows 10 Pro | Price: $609.99\n",
      "-----------------------------------\n",
      "33) LG Gram 14\" Full HD IPS MIL-Spec Notebook Computer, Intel Core i7-8565U 1.8GHz, 16GB RAM, 256GB SSD, Windows 10 Home, Dark Silver | Price: $1,196.99\n",
      "-----------------------------------\n",
      "34) HP 240 G6 14\" HD Notebook, Intel Dual-Core N4000 Upto 2.6GHz, 16GB RAM, 256GB SSD, VGA, HDMI, LAN, Card Reader, Wi-Fi, Bluetooth, Windows 10 Home | Price: $599.99\n",
      "-----------------------------------\n",
      "35) HP 240 G6 14\" HD Notebook, Intel Dual-Core i3-6006U 2.0GHz, 16GB RAM, 256GB SSD, DVD-RW, VGA, HDMI, Card Reader, Wi-Fi, Bluetooth, Windows 10 Pro | Price: $569.99\n",
      "-----------------------------------\n",
      "36) Panasonic Toughbook CF-53, Intel Core i5-4310U @2.0GHz, 14'' HD, WiFi, Bluetooth, Insertable Smartcard, DVD-RW, Windows Pro | Price: $1,719.60\n",
      "-----------------------------------\n",
      "============================================================\n",
      "36 Scrappable Objects on the page. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Break Pedal: Answer any robot queries by NewEgg. Enter \"y\" when you are ready to proceed. y\n",
      "Proceeding with webscrape... \n",
      "1) | SLEEPING FOR 16 SECONDS \n",
      "2) | SLEEPING FOR 11 SECONDS \n",
      "3) | SLEEPING FOR 6 SECONDS \n",
      "4) | SLEEPING FOR 12 SECONDS \n",
      "5) | SLEEPING FOR 5 SECONDS \n",
      "6) | SLEEPING FOR 22 SECONDS \n",
      "All 7 pages have been saved in the \"processing\" folder (1 page = csv files). Would you like for us concatenate all the files into one? Enter \"y\", if so. Otherwise, enter anykey to exit the program. y\n",
      "WebScraping Complete! All 7 have been scraped and saved as 2020-04-12_21.13.12_LaptopsNotebooks_scraped_7_pages_.csv in the \"finished_outputs\" folder\n",
      "The \"processing\" folder has 7 csv files of each page that was scraped. Would you like to clear the files? Enter \"y\", if so. Otherwise, enter anykey to exit the program. n\n",
      "Thank you and hope you found this useful!\n"
     ]
    }
   ],
   "source": [
    "# scrape_again = 'y'\n",
    "# while scrape_again =='y':\n",
    "#     print(\"=== NewEgg.Com WebScraper Beta ===\")\n",
    "#     print(\"==\"*30)\n",
    "#     print(\"Instructions:\")\n",
    "#     print(\"(1) Go to www.newegg.com, search for the product and filter for your requirements (e.g. brand and specifications) \")\n",
    "#     print(\"(2) Copy and paste the url from your exact search \")\n",
    "#     print('(3) Activate or Disable the \"Head View\", webscraper bots point of view ')\n",
    "#     print('(4) Check the \"final_output folder when the webscraper bot is done scraping \"')\n",
    "#     print(\"\")\n",
    "# # NEED TO CREATE LAST INPUT TO LOOP THIS WHOLE THING AGAIN.\n",
    "# Maybe use pandas to provide summary of data\n",
    "# Export images of box and whisker plots using statistics by brand\n",
    "\n",
    "return_dt()\n",
    "\n",
    "executable_path = {'executable_path': './chromedriver.exe'}\n",
    "\n",
    "url = input(\"Step 1) Please copy and paste your laptop query that you want to webscrape, and press enter: \")\n",
    "head = ''\n",
    "browser =''\n",
    "head_on_off(executable_path)\n",
    "response = requests.get(current_url)\n",
    "#response\n",
    "\n",
    "current_page_soup = soup(response.text, 'html.parser')\n",
    "current_page_soup.find_all(\"div\", class_=\"item-container\")\n",
    "scrappable_y_n(current_page_soup)\n",
    "\n",
    "# Are there any pop ups / safe to proceed?\n",
    "safe_proceed_y_n = input(f'The Break Pedal: Answer any robot queries by NewEgg. Enter \"y\" when you are ready to proceed. ')\n",
    "if safe_proceed_y_n == 'y':\n",
    "    print(f'Proceeding with webscrape... ')\n",
    "else:\n",
    "    print(\"Quitting browser. You will need to press ctrl + c to quit, and then restart the program to try again. \")\n",
    "    browser.quit()\n",
    "#newegg_page_scraper(containers)\n",
    "\n",
    "# will need to UNCOMMENT AFTER\n",
    "results_pages()\n",
    "\n",
    "#page_turner(total_results_pages)\n",
    "\n",
    "#total_results_pages = 5\n",
    "for turn_page in range(1, total_results_pages):\n",
    "    # set the current url as the target page (aiming the boomerang)\n",
    "    target_url = browser.url\n",
    "\n",
    "    # Use Request.get() - throw the boomerang at the target, retrieve the info, & return back to requestor\n",
    "    response_target = requests.get(target_url)\n",
    "    #response\n",
    "\n",
    "    # Use BeautifulSoup to read grab all the HTML using the lxml parser\n",
    "    target_page_soup = soup(response_target.text, 'html.parser')\n",
    "\n",
    "    # Use BeautifulSoup to extract the total results page number\n",
    "    #results_pages = current_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "\n",
    "    results_pages = target_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "    #=========================================================\n",
    "    containers = target_page_soup.find_all(\"div\", class_=\"item-container\")\n",
    "\n",
    "    newegg_page_scraper(containers, turn_page)\n",
    "\n",
    "    #for i in range(total_results_pages):\n",
    "    x = random.randint(3, 25)\n",
    "    print(f\"{turn_page}) | SLEEPING FOR {x} SECONDS \")\n",
    "    time.sleep(x)\n",
    "\n",
    "    browser.find_by_xpath('//*[@id=\"bodyArea\"]/section/div/div/div[2]/div/div/div/div[2]/div[1]/div[2]/div[1]/div[2]/div/div[2]/button').click()\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "\n",
    "##################################################################\n",
    "concat_y_n = input(f'All {total_results_pages} pages have been saved in the \"processing\" folder (1 page = csv files). Would you like for us concatenate all the files into one? Enter \"y\", if so. Otherwise, enter anykey to exit the program. ')\n",
    "if concat_y_n == 'y':\n",
    "    concatenate(total_results_pages)\n",
    "    print(f'WebScraping Complete! All {total_results_pages} have been scraped and saved as {current_date}_{product_category}_scraped_{total_results_pages}_pages_.csv in the \"finished_outputs\" folder')\n",
    "\n",
    "# clear out processing folder function here - as delete everything to prevent clutter\n",
    "clear_processing_y_n = input(f'The \"processing\" folder has {total_results_pages} csv files of each page that was scraped. Would you like to clear the files? Enter \"y\", if so. Otherwise, enter anykey to exit the program. ')\n",
    "if clear_processing_y_n == 'y':\n",
    "    clean_processing_fldr()\n",
    "\n",
    "    \n",
    "print('Thank you and hope you found this useful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
