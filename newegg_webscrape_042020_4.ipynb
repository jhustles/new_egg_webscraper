{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebScraping NewEgg.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "from re import search\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "#import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "# conn = 'mongodb://localhost:27017'\n",
    "# client = pymongo.MongoClient(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define database\n",
    "# db = client.newegg_laptops_db\n",
    "# # Define collection\n",
    "# collection = db.apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Splinter and BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was not a possible answer. \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was not a possible answer. \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO 2\n"
     ]
    }
   ],
   "source": [
    "# Function to ask users if they want to watch the Bot (headless = False) work OR not (headless = True)\n",
    "\n",
    "head = ''\n",
    "browser =''\n",
    "def head_on_off():\n",
    "    global head\n",
    "    global browser\n",
    "    options = [1, 2]\n",
    "    executable_path = {'executable_path': './chromedriver.exe'}\n",
    "    # For all cases where users input in a value that is not valid.\n",
    "    while head not in options:\n",
    "        head = int(input('Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO'))\n",
    "        if head not in options:\n",
    "            print(\"That was not a valid answer. Please try again. \")\n",
    "            \n",
    "    # For cases where users enter in valid options:\n",
    "    if head == options[0]:\n",
    "        browser = Browser('chrome', **executable_path, headless=False)\n",
    "    if head == options[1]:\n",
    "        browser = Browser('chrome', **executable_path, headless=True)\n",
    "\n",
    "\n",
    "head_on_off()\n",
    "#print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was not a possible answer. \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was not a possible answer. \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want the desktop watch the bot work? Enter a number: 1 - YES | 2 - NO 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Have not sucessfully, created a function to output a variable that can be passed into broswer.\n",
    "# Maybe ask someone.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = Browser('chrome', **executable_path, headless=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up url that you want to scrape\n",
    "#url = 'https://www.newegg.com/p/pl?N=100006740&page=1&order=RELEASE'\n",
    "url = 'https://www.newegg.com/'\n",
    "\n",
    "# Splinter uses browser to go directly to the url\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Query and Selectable Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Input\n",
    "\n",
    "query_input = input('Enter Product Search (e.g. \"laptops\", \"monitors\", \"mouse\"): ')\n",
    "#query_input = \"Laptops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_input = query_input.lower().strip().replace(\" \", \"\")\n",
    "query_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_url = browser.url #+ '&Page=' #+ str(turn_page)\n",
    "\n",
    "# Use Request.get() to pull the current url\n",
    "response = requests.get(current_url)\n",
    "#response\n",
    "\n",
    "# Use BeautifulSoup to grab all the HTML using the lxml parser\n",
    "current_page_soup = soup(response.text, 'html.parser')\n",
    "\n",
    "search_box = browser.find_by_id(\"SearchBox2020\").type(query_input)\n",
    "submit = browser.find_by_css(\".fa-search\").first.click()\n",
    "time.sleep(2)\n",
    "# Click on the first element which is laptops / notebooks on the side menu far target by class\n",
    "browser.find_by_css(\".filter-box-label\").first.click()\n",
    "time.sleep(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_by_css(\".filter-box-label\")#[4].click()\n",
    "\n",
    "#btn btn-tool btn-mini filter-box-apply\n",
    "\n",
    "len(browser.find_by_css(\".filter-box-label\"))\n",
    "\n",
    "browser.find_by_css(\".filter-box-label\")[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_url = browser.url\n",
    "response = requests.get(current_url)\n",
    "current_page_soup = soup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "containers = current_page_soup.find_all(\"div\", class_=\"item-container\")\n",
    "len(containers)\n",
    "con = containers[0]\n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (key) model / (id within the HTML doc)\n",
    "# list of dictionaries of possible laptop specifications\n",
    "all_specs = [laptop_types, cpu_types, ram, screen_size, condition]\n",
    "\n",
    "laptop_types = {\n",
    "    \"laptops/notebooks\": '(\".filter-box-label\")[0]',\n",
    "    \"gaminglaptops\": '(\".filter-box-label\")[1]',\n",
    "    \"2-in-1laptops\": '(\".filter-box-label\")[2]',\n",
    "    \"chromebooks\": '(\".filter-box-label\")[3]',\n",
    "    \"mobileworkstations\": '(\".filter-box-label\")[4]'\n",
    "}\n",
    "\n",
    "\n",
    "cpu_types = {\n",
    "    \"amdryzen7\": \"601307583\",\n",
    "    \"amdryzen5\": \"601346405\",\n",
    "    \"amdryzen3\": \"601346404\",\n",
    "    \"intelcorei9\": \"601346404\",\n",
    "    \"intelcorei7\": \"601286795\",\n",
    "    \"intelcorei5\": \"601286800\",\n",
    "    \"intelcorei3\": \"601286796\"\n",
    "}\n",
    "\n",
    "ram = {\n",
    "    \"128gb\": \"601274231\",\n",
    "    \"64gb\": \"601107729\",\n",
    "    \"48gb\": \"601349624\",\n",
    "    \"40gb\": \"601331008\",\n",
    "    \"32gb\": \"600337010\",\n",
    "    \"24gb\": \"600440394\"\n",
    "}\n",
    "\n",
    "# took out the \" inch sign, so when you search the key, all lowercase and replace the inch sign ' \" '\n",
    "screen_size = {\n",
    "    \"11.6andsmaller\": \"600004340\",\n",
    "    \"12-13.5\": \"600004341\",\n",
    "    \"14-14.5\": \"600004343\",\n",
    "    \"15-15.6\": \"600004344\",\n",
    "    \"16-16.4\": \"600004345\",\n",
    "    \"17-17.3\": \"600004346\",\n",
    "    # for TV's - may take out or create seperate list of TV screen sizes\n",
    "    \"upto24\": \"600453408\",\n",
    "    \"25-39\": \"600453409\",\n",
    "    \"40-49\": \"600453410\",\n",
    "    \"50-59\": \"600453411\",\n",
    "    \"60andup\": \"600453412\"\n",
    "}\n",
    "# \n",
    "\n",
    "# this is same for TV and laptops, need to verify for other parts of the site\n",
    "condition = {\n",
    "    \"New\": \"4814\",\n",
    "    \"Refurbished\": \"4016\",\n",
    "    \"Used\": \"4823\",\n",
    "    \"OpenBox\": \"4809\"\n",
    "}\n",
    "\n",
    "\n",
    "#print(all_specs[1]['amdryzen7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to figure out how to implement classes for OOP\n",
    "class laptop_specs:\n",
    "    def __init__(self, model, id_path):\n",
    "        self.model = model\n",
    "        self.id_path\n",
    "    \n",
    "    def select_option(self):\n",
    "        pass\n",
    "    \n",
    "    def apply(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draft design of a function to use on classes\n",
    "def check_AMD_Ryzen7(amd_Ryzen7_selected):\n",
    "    browser.find_by_xpath('//*[@id=\"facet600003942\"]/dd/ul[1]/li[1]/div/label/span').click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Logic - figure out at least 3 routes and program. general event: laptop or laptops\n",
    "if (query_input == 'laptop' | 'laptops'):\n",
    "    search_box = browser.find_by_id(\"SearchBox2020\").type(query_input)\n",
    "    submit = browser.find_by_css(\".fa-search\").first.click()\n",
    "    time.sleep(2)\n",
    "    # Click on the first element which is laptops / notebooks on the side menu far target by class\n",
    "    browser.find_by_css(\".filter-box-label\").first.click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # next can add the options of particular laptop features people would typically want\n",
    "    browser.click_link_by_id(\"601307583\")\n",
    "    \n",
    "    \n",
    "# In the event they put in a laptop brand and extra details\n",
    "elif search(\"laptop\", query_input):\n",
    "    # Find the search bar, and type in \"laptops\"\n",
    "    search_box = browser.find_by_id(\"SearchBox2020\").type(query_input)\n",
    "    submit = browser.find_by_css(\".fa-search\").first.click()\n",
    "    browser.find_by_css(\".filter-box-label\").first.click()\n",
    "    time.sleep(4)\n",
    "    #browser.find_by_id(\"601307583\").click()\n",
    "\n",
    "else: #this is default all else products\n",
    "    search_box = browser.find_by_id(\"SearchBox2020\").type(query_input)\n",
    "    submit = browser.find_by_css(\".fa-search\").first.click()\n",
    "    # new, refurbished, or brand new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This \"apply\" button works only if they select a CPU type first\n",
    "#browser.find_by_id(\"fab_600003942\").click()\n",
    "\n",
    "# MEMORY (RAM) Apply button works\n",
    "#browser.find_by_id(\"fab_600004790\").click()\n",
    "\n",
    "# SSD apply button works!\n",
    "#browser.find_by_id(\"fab_600422833\").click()\n",
    "\n",
    "# Screen Size Apply works!\n",
    "#browser.find_by_id(\"fab_600004339\").click()\n",
    "\n",
    "# Price Apply button does work as well *******\n",
    "\n",
    "#min_price = input(\"Minimum Price\")\n",
    "min_price = '500'\n",
    "\n",
    "#max_price = input(\"Maximum Price\")\n",
    "max_price = '2000'\n",
    "\n",
    "browser.find_by_id(\"txtLeftNavPriceMin\").click().type(min_price)\n",
    "browser.find_by_id(\"txtLeftNavPriceMax\").click().type(max_price)\n",
    "\n",
    "# Price Apply Button\n",
    "browser.find_by_id(\"fab_4015\").click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative way to PRICE FILTER !!!!\n",
    "\n",
    "#min_price = input(\"Minimum Price\")\n",
    "min_price = '500'\n",
    "\n",
    "#max_price = input(\"Maximum Price\")\n",
    "max_price = '2000'\n",
    "\n",
    "url_price = f\"https://www.newegg.com/p/pl?N=100006740&LeftPriceRange={min_price}%20{max_price}\"\n",
    "browser.visit(url_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click the Search button!\n",
    "\n",
    "submit = browser.find_by_css(\".fa-search\").first.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the first element which is laptops / notebooks on the side menu far target by class\n",
    "# Optional - can expand this out later for other options\n",
    "\n",
    "browser.find_by_css(\".filter-box-label\").first.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on \"Sold By: Newegg\" - later add options for each type (later code by xpath for each option)\n",
    "\n",
    "browser.find_by_css(\".form-radiobox-title\").first.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newegg_page_scraper(containers, turn_page):\n",
    "    \n",
    "    images = []\n",
    "    product_brands = []\n",
    "    product_models = []\n",
    "    product_links = []\n",
    "    item_numbers = []\n",
    "    promotions = []\n",
    "    prices = []\n",
    "    shipping_terms = []\n",
    "    page_nums = []\n",
    "    \n",
    "    \n",
    "    for con in containers:\n",
    "        page_counter = turn_page\n",
    "        page_nums.append(int(turn_page))\n",
    "        \n",
    "\n",
    "        image = con.a.img[\"src\"]\n",
    "        images.append(image)\n",
    "        \n",
    "        brand_name = con.find_all('a', class_=\"item-brand\")[0].img[\"title\"]\n",
    "        product_brands.append(brand_name)\n",
    "        #print(brand_name)\n",
    "\n",
    "        prd_title = con.find_all('a', class_=\"item-title\")[0].text\n",
    "        product_models.append(prd_title)\n",
    "        \n",
    "        product_link = con.find_all('a', class_=\"item-title\")[0]['href']\n",
    "        product_links.append(product_link)\n",
    "        \n",
    "        item_num = con.find_all('a', class_=\"item-title\")[0]['href'].split('?')[1].split('=')[1]\n",
    "        item_numbers.append(item_num)\n",
    "        \n",
    "        current_promo = con.find_all(\"p\", class_=\"item-promo\")[0].text\n",
    "        promotions.append(current_promo)\n",
    "\n",
    "        price = con.find_all('li', class_=\"price-current\")[0].text.split()[0]\n",
    "        prices.append(price)\n",
    "\n",
    "        shipping = con.find_all('li', class_='price-ship')[0].text.strip()\n",
    "        shipping_terms.append(shipping)\n",
    "        \n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "    'item_number': item_numbers,\n",
    "    'brand': product_brands,\n",
    "    'model_specifications': product_models,\n",
    "    'price': prices,\n",
    "    'current_promotions': promotions,\n",
    "    'shipping': shipping_terms,\n",
    "    'page_number': page_nums,\n",
    "    'product_links': product_links,\n",
    "    'image_link': images\n",
    "    })\n",
    "\n",
    "    return df.to_csv(f'./processing/{current_date}_{query_input}_{page_counter}_scraped.csv')\n",
    "    \n",
    "#newegg_page_scraper(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(total_results_pages):\n",
    "    \n",
    "    path = f'./processing\\\\'\n",
    "    scraped_pages = glob.glob(path + \"/*.csv\")\n",
    "    concatenate_pages = []\n",
    "\n",
    "    for page in scraped_pages:\n",
    "        df = pd.read_csv(page, index_col=0, header=0)\n",
    "        concatenate_pages.append(df)\n",
    "\n",
    "    compiled_data = pd.concat(concatenate_pages, axis=0, ignore_index=True)\n",
    "    concatenated_output = compiled_data.to_csv(f\"./finished_outputs/{current_date}_{query_input}_scraped_{total_results_pages}_pages_.csv\")\n",
    "    return concatenated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circle back to this\n",
    "def clean_processing_fldr():\n",
    "    # delete all files in the 'processing folder'\n",
    "    path = f'./processing\\\\'\n",
    "    scraped_pages = glob.glob(path + \"/*.csv\")\n",
    "    clear_processing_files = []\n",
    "\n",
    "    for page in scraped_pages:\n",
    "        os.remove(page)\n",
    "        \n",
    "    return 'Clearing of \"Processing\" folder complete. '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Egg WebScraper Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally used this but found a way to integrate it into the loop to prevent \"requesting\" from the website as minimal as possible.\n",
    "\n",
    "# Extract total page numbers from results\n",
    "#=================================================\n",
    "# Setup current date - for later use\n",
    "current_date = str(datetime.datetime.now()).replace(':','.').replace(' ','_')[:-7]\n",
    "\n",
    "# Use Splinter to grab the current url, to setup request to pull URL\n",
    "current_url = browser.url #+ '&Page=' #+ str(turn_page)\n",
    "\n",
    "# Use Request.get() to pull the current url\n",
    "response = requests.get(current_url)\n",
    "#response\n",
    "\n",
    "# Use BeautifulSoup to grab all the HTML using the lxml parser\n",
    "current_page_soup = soup(response.text, 'html.parser')\n",
    "\n",
    "# Use BeautifulSoup to extract the total results page number\n",
    "results_pages = current_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "time.sleep(1)\n",
    "\n",
    "# Find and extract total pages + and add 1 to ensure proper length of total pages\n",
    "total_results_pages = int(re.split(\"/\", results_pages)[1]) - 30 #+ 2 # need to add 2 b/c 'range(inclusive, exclusive)'\n",
    "\n",
    "## Comparing the differences between page one url and page 2's url\n",
    "# https://www.newegg.com/p/pl?N=100006740%208000&ActiveSearchResult=True\n",
    "# https://www.newegg.com/p/pl?N=100006740%208000&ActiveSearchResult=True&Page=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is \"NEXT PAGE BUTTON CLICK\" - This loops thru the total amount of pages by clicking the next page button\n",
    "for turn_page in range(1, total_results_pages):\n",
    "    # set the current url as the target page (aiming the boomerang)\n",
    "    target_url = browser.url\n",
    "    \n",
    "    # Use Request.get() - throw the boomerang at the target, retrieve the info, & return back to requestor\n",
    "    response_target = requests.get(target_url)\n",
    "    #response\n",
    "    \n",
    "    # Use BeautifulSoup to read grab all the HTML using the lxml parser\n",
    "    target_page_soup = soup(response_target.text, 'html.parser')\n",
    "\n",
    "    # Use BeautifulSoup to extract the total results page number\n",
    "    results_pages = current_page_soup.find_all('span', class_=\"list-tool-pagination-text\")[0].text.strip()\n",
    "    \n",
    "    #=========================================================\n",
    "    containers = target_page_soup.find_all(\"div\", class_=\"item-container\")\n",
    "    newegg_page_scraper(containers, turn_page)\n",
    "    time.sleep(4)\n",
    "    browser.find_by_xpath('//*[@id=\"bodyArea\"]/section/div/div/div[2]/div/div/div/div[2]/div[1]/div[2]/div[1]/div[2]/div/div[2]/button').click()\n",
    "    \n",
    "browser.quit()\n",
    "concatenate(total_results_pages)\n",
    "clean_processing_fldr()\n",
    "# clear out processing folder function here - as delete everything to prevent clutter\n",
    "\n",
    "\n",
    "print(f'WebScraping Complete! All {total_results_pages} have been scraped and saved as {current_date}_{query_input}_scraped_{total_results_pages}_pages_.csv in the \"finished_outputs\" folder')\n",
    "print('Thank you and hope you found this useful!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page Scraper And Exports Out to CSV. Later can figure out how to get it out to PyMongo / Mongo Db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.a.img[\"src\"]\n",
    "con.find_all('a', class_=\"item-title\")[0]['href'].split('?')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the loop to extract: brand, Title of the product, price-dollar, price-cents,\n",
    "# shipping\n",
    "\n",
    "\n",
    "#def newegg_page_scraper(containers, turn_page):\n",
    "def newegg_page_scraper(containers):\n",
    "    item_numbers = []\n",
    "    laptop_brands = []\n",
    "    laptop_models = []\n",
    "    product_links = []\n",
    "    laptop_prices = []\n",
    "    laptop_shipping = []\n",
    "    laptop_images = []\n",
    "    promotions = []\n",
    "    \n",
    "    for con in containers:\n",
    "\n",
    "        page_counter = turn_page\n",
    "        \n",
    "        item_num = con.find_all('a', class_=\"item-title\")[0]['href'].split('?')[1]\n",
    "        item_numbers.append(item_num)\n",
    "        \n",
    "        brand_name = con.find_all('a', class_=\"item-brand\")[0].img[\"title\"]\n",
    "        laptop_brands.append(brand_name)\n",
    "        #print(brand_name)\n",
    "\n",
    "        prd_title = con.find_all('a', class_=\"item-title\")[0].text\n",
    "        laptop_models.append(prd_title)\n",
    "        \n",
    "        product_link = con.find_all('a', class_=\"item-title\")[0]['href']\n",
    "        product_links.append(product_link)\n",
    "        \n",
    "        price = con.find_all('li', class_=\"price-current\")[0].text.split()[0]\n",
    "        laptop_prices.append(price)\n",
    "\n",
    "        shipping = con.find_all('li', class_='price-ship')[0].text.strip()\n",
    "        laptop_shipping.append(shipping)\n",
    "        \n",
    "        image = con.a.img[\"src\"]\n",
    "        laptop_image.append(image)\n",
    "        \n",
    "        # add this and the list up top\n",
    "        current_promo = con.find_all(\"p\", class_=\"item-promo\")[0].text\n",
    "        promotions.append(current_promo)\n",
    "        \n",
    "        #if statements for the price-was and for sale ending - optional\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "    'brand': laptop_brands,\n",
    "    'model_listing': laptop_models,\n",
    "    'price': laptop_prices,\n",
    "    'shipping': laptop_shipping\n",
    "    })\n",
    "\n",
    "    return df.to_csv(f'./output/newgg_laptops_{page_counter}.csv')\n",
    "    \n",
    "newegg_page_scraper(containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
